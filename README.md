The project is based on real time tracking of human face for controlling the mouse cursor. This project aims to come up with the system that will eliminate the need of touch to mouse pad to control the cursor. The system will use facial movements as triggers for cursor movement on the screen. The user’s real time video for the mouse movement is captured using a webcam. The mouse clicks are done in two ways namely 1) Natural Language Processing (NLP) 2) Eye based. 
In NLP based the mouse clicks are done through voice commands made by the user. The commands passed could be for a click, right click, left click, double click, scroll up and scroll down. Python’s Speech Recognition modules along with few other built-in packages are been used to create the project. Under eye-based mouse control, the cursor movements done are same as in the case of NLP based. The mouse button clicks are done through blink of an eye. 


